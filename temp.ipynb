{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import huggingface_hub\n",
    "import wandb\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from time import time\n",
    "import gc\n",
    "import json\n",
    "import argparse\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import fire\n",
    "import inspect\n",
    "\n",
    "\n",
    "logg = lambda x: print(f\"------------------------ {x} ---------------------------\")\n",
    "\n",
    "ME = \"/dpc/kunf0097/l3-8b\"\n",
    "\n",
    "\n",
    "def inspectt(frame):\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    for arg in args:\n",
    "        print(f\"\\t{arg}: {values[arg]}\")\n",
    "    logg(\"\")\n",
    "\n",
    "\n",
    "def get_tokenizer_and_model(model_name: str, cache_dir: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=f\"{cache_dir}/tokenizer\",\n",
    "        pad_token_id=0,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=f\"{cache_dir}/model\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        offload_buffers=True,\n",
    "    )\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def tokenize(prompt, tokenizer):\n",
    "    tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point, tokenizer, prompt=None):\n",
    "    if prompt is None:\n",
    "        prompt = \"\"\"<|start_header_id|>system<|end_header_id|> {}<|eot_id|><|start_header_id|>user<|end_header_id|> {}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    prompt = prompt.format(data_point[\"instruction\"], data_point[\"input\"])\n",
    "    tokenized_full_prompt = tokenize(prompt, tokenizer=tokenizer)\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "\n",
    "def eval_prompt_tokenizer(generated, output, eval_tokenizer, prompt=None):\n",
    "    prompt = prompt.format(generated, output)\n",
    "    tokenized_full_prompt = tokenize(prompt, tokenizer=eval_tokenizer)\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "\n",
    "def extract_score(text):\n",
    "    match = re.search(r\"\\b\\d+\\.\\d+\\b\", text)\n",
    "    return float(match.group(0)) if match else -1.0\n",
    "\n",
    "\n",
    "def log2json(results, json_result):\n",
    "    # Write back the updated results\n",
    "    with open(json_result, \"w\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"./out\"\n",
    "cache_dir = f\"{ME}\"\n",
    "eval_data_path = \"./data/1/eval_sample.json\"\n",
    "log_file = None\n",
    "name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "eval_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "run_id = datetime.now().strftime(\"%y%m%d%H%M%S\")\n",
    "log2wandb: bool = True\n",
    "project = \"huggingface\"\n",
    "entity = \"my-ku-org\"\n",
    "eval_prompt_path = None\n",
    "evals_per_example = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log2wandb and (project is None or entity is None):\n",
    "    raise ValueError(\"Both 'project' and 'entity' must be set if 'log2wandb' is True.\")\n",
    "\n",
    "if log_file is None:\n",
    "    log_file = f\"{output_dir}/results_{name.split('/')[1]}_{run_id}.json\"\n",
    "\n",
    "if eval_prompt_path is None:\n",
    "    evaluator_prompt = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "You are going to act as an LLM evaluator to rate the answer of the medical chatbot on factualness (i.e how contextually the generated output followed the expected reply). Penalize it appropriately for any hallucination, lost of context, or trailing repetition. YOUR RESPONSE IS NOTHING ELSE BUT A FLOAT FROM 0.0 - 5.0 (with format x.x). Where 0.0 indicates the context of the generated response is very far from the expected one. And 5.0 represents otherwise. AGAIN IF YOUR GENERATED ANYTHING ELSE BUT A FLOAT YOU'RE GOING TO CRUSH MY SYSTEM!!<|eot_id|><|start_header_id|>user<|end_header_id|> \n",
    "### Expected: {}\n",
    "### Generated: {}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "else:\n",
    "    with open(eval_prompt_path, \"r\") as f:\n",
    "        evaluator_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/kunet.ae/ku5001069/.cache/huggingface/token\n",
      "Login successful\n",
      "------------------------ 240702151059 ---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1057cb21ec4698af23ac18b089eeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787abe1a11e24bad8689e739a3ae46c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time()\n",
    "load_dotenv()\n",
    "HF_TOKEN_WRITE = os.getenv(\"HF_TOKEN_WRITE\")\n",
    "huggingface_hub.login(token=HF_TOKEN_WRITE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "logg(run_id)\n",
    "\n",
    "evaluator_tokenizer, evaluator_model = get_tokenizer_and_model(\n",
    "    model_name=eval_name, cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "candidate_tokenizer, candidate_model = get_tokenizer_and_model(\n",
    "    model_name=name, cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_dataset(\"json\", data_files=eval_data_path)\n",
    "eval_dataset = data[\"train\"].map(\n",
    "    lambda x: generate_and_tokenize_prompt(\n",
    "        x, candidate_tokenizer, phi_prompt\n",
    "    )\n",
    ")  # not shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"If you are a doctor, please answer the medical questions based on the patient's description.\",\n",
       " 'input': 'my mothers age 58, jaundice problemcreatinine 4.88, sodium-125, potasium-4.6; chloride-85;bilirubin total-17.16;bilirubin direct-2.38;sgot-155;sgpt-160;alkaline phos-260;protein-7.54;albumin-3.4;urea-138 and BP 30nowplease help. what is status and in which stage she is?',\n",
       " 'output': 'Hi thanks for contacting Chat Doctor.... Your liver enzymes are high....with increased bilirubin. Your albumin level low ....so you are having chronic liver problem.... You might have cirrhosis or chronic hepatitis.... For grading liver biopsy needed... Your physical examination must be done for splenomegaly and ascites..... If portal hypertension present beta blocker needed... For jaundice fruits taken more.... Excess fatty diet avoided.... Sugar cane juice, apple juice taken more.... Avoid strenuous work.... Consult gastroenterologist for detail examination and further opinion... Take care.... Chat Doctor.',\n",
       " 'prompt': \"<|start_header_id|>system<|end_header_id|> If you are a doctor, please answer the medical questions based on the patient's description.<|eot_id|><|start_header_id|>user<|end_header_id|> This is the question: my mothers age 58, jaundice problemcreatinine 4.88, sodium-125, potasium-4.6; chloride-85;bilirubin total-17.16;bilirubin direct-2.38;sgot-155;sgpt-160;alkaline phos-260;protein-7.54;albumin-3.4;urea-138 and BP 30nowplease help. what is status and in which stage she is?<|eot_id|><|start_header_id|>assistant<|end_header_id|> Hi thanks for contacting Chat Doctor.... Your liver enzymes are high....with increased bilirubin. Your albumin level low ....so you are having chronic liver problem.... You might have cirrhosis or chronic hepatitis.... For grading liver biopsy needed... Your physical examination must be done for splenomegaly and ascites..... If portal hypertension present beta blocker needed... For jaundice fruits taken more.... Excess fatty diet avoided.... Sugar cane juice, apple juice taken more.... Avoid strenuous work.... Consult gastroenterologist for detail examination and further opinion... Take care.... Chat Doctor.<|eot_id|>\",\n",
       " 'input_ids': [[32006,\n",
       "   960,\n",
       "   366,\n",
       "   526,\n",
       "   263,\n",
       "   11619,\n",
       "   29892,\n",
       "   3113,\n",
       "   1234,\n",
       "   278,\n",
       "   16083,\n",
       "   5155,\n",
       "   2729,\n",
       "   373,\n",
       "   278,\n",
       "   16500,\n",
       "   29915,\n",
       "   29879,\n",
       "   6139,\n",
       "   29889,\n",
       "   32007,\n",
       "   32010,\n",
       "   590,\n",
       "   25550,\n",
       "   414,\n",
       "   5046,\n",
       "   29871,\n",
       "   29945,\n",
       "   29947,\n",
       "   29892,\n",
       "   432,\n",
       "   585,\n",
       "   299,\n",
       "   625,\n",
       "   1108,\n",
       "   1037,\n",
       "   21203,\n",
       "   457,\n",
       "   29871,\n",
       "   29946,\n",
       "   29889,\n",
       "   29947,\n",
       "   29947,\n",
       "   29892,\n",
       "   20892,\n",
       "   1974,\n",
       "   29899,\n",
       "   29896,\n",
       "   29906,\n",
       "   29945,\n",
       "   29892,\n",
       "   3104,\n",
       "   294,\n",
       "   1974,\n",
       "   29899,\n",
       "   29946,\n",
       "   29889,\n",
       "   29953,\n",
       "   29936,\n",
       "   521,\n",
       "   5095,\n",
       "   680,\n",
       "   29899,\n",
       "   29947,\n",
       "   29945,\n",
       "   29936,\n",
       "   18152,\n",
       "   381,\n",
       "   431,\n",
       "   262,\n",
       "   3001,\n",
       "   29899,\n",
       "   29896,\n",
       "   29955,\n",
       "   29889,\n",
       "   29896,\n",
       "   29953,\n",
       "   29936,\n",
       "   18152,\n",
       "   381,\n",
       "   431,\n",
       "   262,\n",
       "   1513,\n",
       "   29899,\n",
       "   29906,\n",
       "   29889,\n",
       "   29941,\n",
       "   29947,\n",
       "   29936,\n",
       "   5311,\n",
       "   327,\n",
       "   29899,\n",
       "   29896,\n",
       "   29945,\n",
       "   29945,\n",
       "   29936,\n",
       "   5311,\n",
       "   415,\n",
       "   29899,\n",
       "   29896,\n",
       "   29953,\n",
       "   29900,\n",
       "   29936,\n",
       "   2235,\n",
       "   284,\n",
       "   457,\n",
       "   1374,\n",
       "   359,\n",
       "   29899,\n",
       "   29906,\n",
       "   29953,\n",
       "   29900,\n",
       "   29936,\n",
       "   14676,\n",
       "   262,\n",
       "   29899,\n",
       "   29955,\n",
       "   29889,\n",
       "   29945,\n",
       "   29946,\n",
       "   29936,\n",
       "   10336,\n",
       "   262,\n",
       "   29899,\n",
       "   29941,\n",
       "   29889,\n",
       "   29946,\n",
       "   29936,\n",
       "   545,\n",
       "   29874,\n",
       "   29899,\n",
       "   29896,\n",
       "   29941,\n",
       "   29947,\n",
       "   322,\n",
       "   350,\n",
       "   29925,\n",
       "   29871,\n",
       "   29941,\n",
       "   29900,\n",
       "   3707,\n",
       "   552,\n",
       "   559,\n",
       "   1371,\n",
       "   29889,\n",
       "   825,\n",
       "   338,\n",
       "   4660,\n",
       "   322,\n",
       "   297,\n",
       "   607,\n",
       "   7408,\n",
       "   1183,\n",
       "   338,\n",
       "   29973,\n",
       "   32007,\n",
       "   32001]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"If you are a doctor, please answer the medical questions based on the patient's description.\",\n",
       " 'input': 'my mothers age 58, jaundice problemcreatinine 4.88, sodium-125, potasium-4.6; chloride-85;bilirubin total-17.16;bilirubin direct-2.38;sgot-155;sgpt-160;alkaline phos-260;protein-7.54;albumin-3.4;urea-138 and BP 30nowplease help. what is status and in which stage she is?',\n",
       " 'output': 'Hi thanks for contacting Chat Doctor.... Your liver enzymes are high....with increased bilirubin. Your albumin level low ....so you are having chronic liver problem.... You might have cirrhosis or chronic hepatitis.... For grading liver biopsy needed... Your physical examination must be done for splenomegaly and ascites..... If portal hypertension present beta blocker needed... For jaundice fruits taken more.... Excess fatty diet avoided.... Sugar cane juice, apple juice taken more.... Avoid strenuous work.... Consult gastroenterologist for detail examination and further opinion... Take care.... Chat Doctor.',\n",
       " 'prompt': \"<|start_header_id|>system<|end_header_id|> If you are a doctor, please answer the medical questions based on the patient's description.<|eot_id|><|start_header_id|>user<|end_header_id|> This is the question: my mothers age 58, jaundice problemcreatinine 4.88, sodium-125, potasium-4.6; chloride-85;bilirubin total-17.16;bilirubin direct-2.38;sgot-155;sgpt-160;alkaline phos-260;protein-7.54;albumin-3.4;urea-138 and BP 30nowplease help. what is status and in which stage she is?<|eot_id|><|start_header_id|>assistant<|end_header_id|> Hi thanks for contacting Chat Doctor.... Your liver enzymes are high....with increased bilirubin. Your albumin level low ....so you are having chronic liver problem.... You might have cirrhosis or chronic hepatitis.... For grading liver biopsy needed... Your physical examination must be done for splenomegaly and ascites..... If portal hypertension present beta blocker needed... For jaundice fruits taken more.... Excess fatty diet avoided.... Sugar cane juice, apple juice taken more.... Avoid strenuous work.... Consult gastroenterologist for detail examination and further opinion... Take care.... Chat Doctor.<|eot_id|>\",\n",
       " 'input_ids': [[32006,\n",
       "   960,\n",
       "   366,\n",
       "   526,\n",
       "   263,\n",
       "   11619,\n",
       "   29892,\n",
       "   3113,\n",
       "   1234,\n",
       "   278,\n",
       "   16083,\n",
       "   5155,\n",
       "   2729,\n",
       "   373,\n",
       "   278,\n",
       "   16500,\n",
       "   29915,\n",
       "   29879,\n",
       "   6139,\n",
       "   29889,\n",
       "   32007,\n",
       "   32010,\n",
       "   590,\n",
       "   25550,\n",
       "   414,\n",
       "   5046,\n",
       "   29871,\n",
       "   29945,\n",
       "   29947,\n",
       "   29892,\n",
       "   432,\n",
       "   585,\n",
       "   299,\n",
       "   625,\n",
       "   1108,\n",
       "   1037,\n",
       "   21203,\n",
       "   457,\n",
       "   29871,\n",
       "   29946,\n",
       "   29889,\n",
       "   29947,\n",
       "   29947,\n",
       "   29892,\n",
       "   20892,\n",
       "   1974,\n",
       "   29899,\n",
       "   29896,\n",
       "   29906,\n",
       "   29945,\n",
       "   29892,\n",
       "   3104,\n",
       "   294,\n",
       "   1974,\n",
       "   29899,\n",
       "   29946,\n",
       "   29889,\n",
       "   29953,\n",
       "   29936,\n",
       "   521,\n",
       "   5095,\n",
       "   680,\n",
       "   29899,\n",
       "   29947,\n",
       "   29945,\n",
       "   29936,\n",
       "   18152,\n",
       "   381,\n",
       "   431,\n",
       "   262,\n",
       "   3001,\n",
       "   29899,\n",
       "   29896,\n",
       "   29955,\n",
       "   29889,\n",
       "   29896,\n",
       "   29953,\n",
       "   29936,\n",
       "   18152,\n",
       "   381,\n",
       "   431,\n",
       "   262,\n",
       "   1513,\n",
       "   29899,\n",
       "   29906,\n",
       "   29889,\n",
       "   29941,\n",
       "   29947,\n",
       "   29936,\n",
       "   5311,\n",
       "   327,\n",
       "   29899,\n",
       "   29896,\n",
       "   29945,\n",
       "   29945,\n",
       "   29936,\n",
       "   5311,\n",
       "   415,\n",
       "   29899,\n",
       "   29896,\n",
       "   29953,\n",
       "   29900,\n",
       "   29936,\n",
       "   2235,\n",
       "   284,\n",
       "   457,\n",
       "   1374,\n",
       "   359,\n",
       "   29899,\n",
       "   29906,\n",
       "   29953,\n",
       "   29900,\n",
       "   29936,\n",
       "   14676,\n",
       "   262,\n",
       "   29899,\n",
       "   29955,\n",
       "   29889,\n",
       "   29945,\n",
       "   29946,\n",
       "   29936,\n",
       "   10336,\n",
       "   262,\n",
       "   29899,\n",
       "   29941,\n",
       "   29889,\n",
       "   29946,\n",
       "   29936,\n",
       "   545,\n",
       "   29874,\n",
       "   29899,\n",
       "   29896,\n",
       "   29941,\n",
       "   29947,\n",
       "   322,\n",
       "   350,\n",
       "   29925,\n",
       "   29871,\n",
       "   29941,\n",
       "   29900,\n",
       "   3707,\n",
       "   552,\n",
       "   559,\n",
       "   1371,\n",
       "   29889,\n",
       "   825,\n",
       "   338,\n",
       "   4660,\n",
       "   322,\n",
       "   297,\n",
       "   607,\n",
       "   7408,\n",
       "   1183,\n",
       "   338,\n",
       "   29973,\n",
       "   32007,\n",
       "   32001]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=eval_dataset[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "outputs = candidate_model.generate(\n",
    "    input_ids=torch.LongTensor(example[\"input_ids\"]).to(candidate_model.device),\n",
    "    attention_mask=torch.LongTensor(example[\"attention_mask\"]).to(candidate_model.device),\n",
    "    **generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ids = outputs[0][len(example[\"input_ids\"][0]) :]\n",
    "response = candidate_tokenizer.decode(response_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log2wandb:\n",
    "    wandb.init(project=project, entity=entity)\n",
    "\n",
    "# generation config\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"eos_token_id\": [\n",
    "        candidate_tokenizer.eos_token_id,\n",
    "        candidate_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
    "    ],\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "1it [00:29, 29.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "2it [01:17, 38.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, example in tqdm(enumerate(eval_dataset)):\n",
    "    res = None\n",
    "    outputs = candidate_model.generate(\n",
    "        input_ids=torch.LongTensor(example[\"input_ids\"]).to(candidate_model.device),\n",
    "        attention_mask=torch.LongTensor(example[\"attention_mask\"]).to(\n",
    "            candidate_model.device\n",
    "        ),\n",
    "        **generation_config,\n",
    "    )\n",
    "\n",
    "    response_ids = outputs[0][len(example[\"input_ids\"][0]) :]\n",
    "    response = candidate_tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "    gt_response = example[\"output\"]  # groundtruth\n",
    "\n",
    "    eval_prompt_tokenized = eval_prompt_tokenizer(\n",
    "        response, gt_response, evaluator_tokenizer, prompt=evaluator_prompt\n",
    "    )\n",
    "\n",
    "    llm_scores = []\n",
    "    for i in range(evals_per_example):\n",
    "        eval_output = evaluator_model.generate(\n",
    "            input_ids=torch.LongTensor(eval_prompt_tokenized[\"input_ids\"]).to(\n",
    "                candidate_model.device\n",
    "            ),\n",
    "            attention_mask=torch.LongTensor(eval_prompt_tokenized[\"attention_mask\"]).to(\n",
    "                candidate_model.device\n",
    "            ),\n",
    "            **generation_config,\n",
    "        )\n",
    "\n",
    "        eval_response = eval_output[0][len(eval_prompt_tokenized[\"input_ids\"][0]) :]\n",
    "        llm_score = evaluator_tokenizer.decode(eval_response, skip_special_tokens=True)\n",
    "        llm_scores.append(extract_score(llm_score))\n",
    "\n",
    "    res = {\n",
    "        \"expected\": gt_response,\n",
    "        \"generated\": response,\n",
    "        \"llm_scores\": llm_scores,\n",
    "        \"avg_llm_score\": sum(llm_scores) / len(llm_scores),\n",
    "    }\n",
    "    results.append(res)\n",
    "    log2json(results, log_file)\n",
    "\n",
    "    if log2wandb:\n",
    "        wandb_log = {\"index\": i, \"avg_llm_score\": res[\"avg_llm_score\"]}\n",
    "        for j, score in enumerate(llm_scores):\n",
    "            wandb_log[f\"llm_score_{j}\"] = score\n",
    "        wandb.log(wandb_log)\n",
    "\n",
    "    del example\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'expected': 'Hi thanks for contacting Chat Doctor.... Your liver enzymes are high....with increased bilirubin. Your albumin level low ....so you are having chronic liver problem.... You might have cirrhosis or chronic hepatitis.... For grading liver biopsy needed... Your physical examination must be done for splenomegaly and ascites..... If portal hypertension present beta blocker needed... For jaundice fruits taken more.... Excess fatty diet avoided.... Sugar cane juice, apple juice taken more.... Avoid strenuous work.... Consult gastroenterologist for detail examination and further opinion... Take care.... Chat Doctor.',\n",
       "  'generated': \"\\n\\nBased on the laboratory results, I'll provide an assessment of your mother's status and stage of liver disease.\\n\\n**Liver Function Tests (LFTs):**\\n\\n* Bilirubin: Total bilirubin is elevated (17.16 mg/dL), indicating liver dysfunction or obstruction. Direct bilirubin (2.38 mg/dL) is also elevated, suggesting that there is some degree of liver cell damage or cholestasis.\\n* Enzymes: Sgot (155 IU/L) and SGPT (160 IU/L) are elevated, indicating liver cell damage or inflammation.\\n* Alkaline phosphatase (260 IU/L) is elevated, suggesting bile duct obstruction or liver cell damage.\\n* Protein and Albumin: Total protein (7.54 g/dL) and albumin (3.4 g/dL) are within normal limits, but albumin is slightly decreased, which may indicate liver dysfunction or malnutrition.\\n\\n**Renal Function Tests (RFTs):**\\n\\n* Creatinine: 4.88 mg/dL is elevated, indicating kidney dysfunction or failure.\\n* Sodium, Potassium, and Chloride: These electrolytes are within normal limits, but potassium (4.6 mmol/L) is slightly decreased, which\",\n",
       "  'llm_scores': [2.3, 1.4],\n",
       "  'avg_llm_score': 1.8499999999999999},\n",
       " {'expected': \"Hello Concerned Person, A chronic heart condition responds well to Homeopathy if the patients' vitality is good. Since you have not mentioned the age of the patient or the actual diagnosis your cardiologist has given, it would be wrong to give a definite idea about the scope of Homeopathy in this case. However, there are some wonderful remedies in Homeopathy for heart failure and arrhythmias. I would recommend you to submit a complete case record with reports and then a call can be taken about treatment. You can mail the reports at Chat Doctor. Com if you would like further guidance. All the best!\",\n",
       "  'generated': \"\\n\\nI'm not a doctor, but I can provide some general information about heart disease and homeopathic treatment.\\n\\nHeart disease, including coronary artery disease, heart failure, and arrhythmias, is a complex condition that requires comprehensive medical care. While homeopathic treatment may be used to manage symptoms and improve quality of life, it is not a cure for heart disease.\\n\\nIn your patient's case, their heart function is significantly impaired, and they have experienced episodes of low blood pressure and heart rate when taking medications for heart beat improvement and blood pressure control. This suggests that their condition is quite severe and requires careful management by a cardiologist.\\n\\nHomeopathic treatment may be used in conjunction with conventional medical care to manage symptoms, improve quality of life, and reduce the risk of complications. However, it is essential to note that homeopathic treatment should not replace conventional medical care, and patients should continue to work with their cardiologist to manage their condition.\\n\\nIn Mumbai, there are several homeopathic doctors who may be able to provide treatment for heart disease. Here are a few options:\\n\\n1. Dr. Nandini S. Desai - Homeopathic Consultant, Mumbai\\nAddress: 202, 2nd Floor, Dhanwantari Building, 14, Juhu Tara Road\",\n",
       "  'llm_scores': [2.4, 2.4],\n",
       "  'avg_llm_score': 2.4}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fa1540936a4adda50e81900407493d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_llm_score_0</td><td>▁</td></tr><tr><td>avg_llm_score_1</td><td>▁</td></tr><tr><td>pcc_0_1</td><td>▁</td></tr><tr><td>run_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_llm_score_0</td><td>2.35</td></tr><tr><td>avg_llm_score_1</td><td>1.9</td></tr><tr><td>pcc_0_1</td><td>1.0</td></tr><tr><td>run_score</td><td>2.125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-surf-121</strong> at: <a href='https://wandb.ai/my-ku-org/huggingface/runs/y1omc4em' target=\"_blank\">https://wandb.ai/my-ku-org/huggingface/runs/y1omc4em</a><br/> View project at: <a href='https://wandb.ai/my-ku-org/huggingface' target=\"_blank\">https://wandb.ai/my-ku-org/huggingface</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_152552-y1omc4em/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if log2wandb:\n",
    "    results_t = list(\n",
    "        zip(*[d[\"llm_scores\"] for d in results])\n",
    "    )  # Transpose to do PCC easier\n",
    "    avg_llm_scores = [d[\"avg_llm_score\"] for d in results]\n",
    "\n",
    "    pcc_results = {\n",
    "        f\"pcc_{i}_{j}\": pearsonr(results_t[i], results_t[j])[0]\n",
    "        for i in range(len(results_t))\n",
    "        for j in range(i + 1, len(results_t))\n",
    "    }  # Calculate PCC for each pair of LLM scores\n",
    "\n",
    "    avg_scores = {\n",
    "        f\"avg_llm_score_{i}\": sum(scores) / len(scores)\n",
    "        for i, scores in enumerate(results_t)\n",
    "    }  # Calculate average scores for each set of LLM scores\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            **avg_scores,\n",
    "            **pcc_results,\n",
    "            \"run_score\": sum(avg_llm_scores) / len(avg_llm_scores),\n",
    "        }\n",
    "    )  # Log the calculated data to wandb\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dpc/kunf0097/l3-8b'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9e39954f9d499e82d53afedbde9615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67ef1585ccc47a3bfde7b22950cbc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246c22a0bb4849a083339a9a8322f9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff32752ad64436baa4b5967bdf0eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723e6813d79e458d8ed96cb7303200b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f7fa757e9649589438b7cc5eaaaa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bb6e2976b846738f8d669313128725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f72eda05404ca185cfe5b7c86f470d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df4c4b6222543039ec7c76d2f1baf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585c56c6263d434e93f29999cc270fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5365065455b64acfa2e31d915fd6ce2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12602bc064249ffad3ab56afd835f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phi_prompt = \"\"\"<|system|>\\n{}<|end|>\\n<|user|>\\n{}<|end|>\\n<|assistant|>\"\"\"\n",
    "candidate_tokenizer, candidate_model = get_tokenizer_and_model(\"microsoft/Phi-3-mini-4k-instruct\", cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "{}<|end|>\n",
      "<|user|>\n",
      "{}<|end|>\n",
      "<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "print(phi_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
